#!/bin/env python3

from typing import Union
from pydantic import BaseModel
from fastapi import FastAPI
import uvicorn
import json
import numpy as np

import torch
import ChatTTS
import torchaudio

import os
import base64
import tempfile

class ReqText(BaseModel):
    text: str
    infercode: dict | None = None
    refinetext: dict | None = None

app = FastAPI()

chat = ChatTTS.Chat()

@app.get("/ping")
def ping():
    return {"status": 200}

# the post
@app.post("/invocations")
def invocations(req: ReqText):
    print(req)
    resp = {}
    wavs = chat.infer(req.text)

    wavstr = []
    for i in range(len(wavs)):
        filename = tempfile.mktemp(dir='')+".wav"
        #torchaudio.save(filename, torch.from_numpy(wavs[i]).unsqueeze(0), 24000, format="wav")
        torchaudio.save(filename, torch.from_numpy(wavs[i]), 24000, format="wav")
        print('saved into '+filename)
        with open(filename, "rb") as wavfile:
            wavstr.append(base64.b64encode(wavfile.read()))
        try:
            os.remove(filename)
        except OSError:
            print("ERROR in rm tmp file "+filename)

    resp['wavs'] = wavstr
    resp['rate'] = '24000'
    resp['encode'] = 'base64'
    print(resp)
    return resp

if __name__ == '__main__':
    chat.load(compile=False)
    uvicorn.run(app, host="0.0.0.0", port=8080)
